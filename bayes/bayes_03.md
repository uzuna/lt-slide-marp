---
marp: true
theme: default
pagination: true
---

# ベイズ統計入門 Vol.3

---

## topic

- 離散の確率分布
- ベイズの定理確率分布編
- PyMC を用いた推定事例

---

## 離散の確率分布

1/2 の意味するところ

---

### ベルヌーイ試行

コインを n 回投げて k 回成功する(=表が出る)例を考える。

${}_nC_k = (a + b)^n$の組み合わせ。パスカルの三角形

$$
1\\
1\space 1\\
1\space 2\space 1\\
1\space 3\space 3\space 1\\
1\space 4\space 6\space 4\space 1\\
1\space 5\space 10\space 10\space 5\space 1\\
$$

---

1 段ごとに組み合わせの数は等比的$2^n$で増える、
全体を 1 としたとき,1 つの組み合わせの比率は$\frac{1}{2}^n$となる
1 つしかない組み合わせが選ばれる確率は回数に応じて等比的に小さくなる

![img](img/03_berntrial_1_2.png)

---

一般化
n 回投げた時の可能性す回べてを足して 1 になるようにする

${}_nC_k \frac{1}{2}^n$

---

### もし成功と失敗の確率が均等でない場合の面積は?

- 公正なコインの表を成功とする: $\theta= \frac{1}{2}$
  $\frac{1}{2}^n = \frac{1}{2}^k (1-\frac{1}{2})^{n-k}$

- 公正 10 面サイコロの内 1 を成功とする: $\theta= \frac{1}{10}$
  $\frac{1}{10}^k (1-\frac{1}{10})^{n-k}$

![height:250px](img/03_berntrial_1_10.png)

---

### 二項分布

確率$\theta$の試行を n 回して k 回成功する確率

$Bin(n, \theta) = {}_nC_k \theta^k(1-\theta)^{n-k}$

ガチャ排出確率 1,5,10%で 10 回試行したときに 1 つでも出る確率
${}_{10}C_1 0.01^1(1-0.01)^{10-1} = 0.0913$
${}_{10}C_1 0.05^1(1-0.05)^{10-1} = 0.3151$
${}_{10}C_1 0.1^1(1-0.1)^{10-1} = 0.38742$

---

二項分布の特性

1. 期待値は$n\theta$
1. 分散 $n\theta(1-\theta)$

$Bin(n, \theta) = {}_nC_k \theta^k(1-\theta)^{n-k}$

![](img/03_binorm_n30.png)

---

ここに試行データ n 回投げて k 回成功がある。
この時適切な$\theta$は何か?

最尤推定: $argmax(L(\theta))$となる$\theta$を選ぶ

最も高いのは期待値$n\theta=\frac{k}{n}$

![](img/03_binorm.png)

---

1 回の試行で表が出るかどうかを知る確率分布 **ベルヌーイ分布**
二項分布の n=1 の特別な形
$\theta$は共通するパラメータ

$$
\begin{aligned}
Bin(n, \theta) &= {}_nC_k \theta^k(1-\theta)^{n-k}\\
Bern(\theta) &= \theta^k(1-\theta)^{1-k}
\end{aligned}
$$

---

## ベイズの定理、確率分布編

ある試行が 10 回中 8 回成功した。
次に表が出る確率を求める

---

### 前提

- 観測データは未知の$\theta$パラメータを持つ分布から得られたとする
- 同じ分布から予測を取り出すことができる

![](img/03_bern_gm.png)

---

謎の分布$\theta$から得たデータは 10 回中 8 回の尤度は以下のようになる

$z=\lbrace 1,0,1,1,1,1,1,0,1,1\rbrace$

$P(z|\theta) = {}_{10}C_8 \theta^8(1-\theta)^2$

---

尤度の形に合わせて、事前確率にベータ関数を用いる

$p(\theta) = Beta(a,b) = \theta^{a-1}(1-\theta)^{b-1}$

$a,b$はハイパーパラメータ。
ベータ関数はパラメータ a,b から$\theta = (0, 1)$を生成する関数
ここでは何も知らない状態として $a=1, b=1$を置く

ベータ分布の期待値 $\frac{a}{a+b}$

---

ベイズの定理に合わせて展開する

$$
\begin{aligned}
p(\theta|z) & = \frac{P(z|\theta)p(\theta)}{\Sigma_{\Theta} P(z|\theta)p(\theta)} \\
& \propto P(z|\theta)p(\theta) \\
& = \theta^8(1-\theta)^2 \theta^{1-1}(1-\theta)^{1-1} + const.
\end{aligned}
$$

分母$\Sigma_{\Theta}$では$\theta$が積分で消えるので無視してしまう
また${}_nC_k$などの正規化項は$\theta$と関係ないので const でまとめる
これを整理すると

$p(\theta|z) = \theta^8(1-\theta)^2$ というベータ分布の事後確率が得られる

---

これをグラフ化すると以下のようになる
![](img/03_beta_11_82.png)

期待値(平均)は$\frac{a}{a+b} = \frac{8}{10} = 0.8$

---

指数を展開することなく事後確率 $Beta(\hat{a}, \hat{b}) = Beta(8,2)$が得られた。

このような尤度と事前事後分布の関係を持つ分布を共役事前分布と呼ぶ

---

共役事前分布

- ベータ分布 $Beta(a, b) -> \theta $
  - ベルヌーイ分布
  - 多試行化 -> 二項分布
- 多次元化 -> ディリクレ分布 $Fir(\alpha_k) -> \pi_k $
  - カテゴリ分布
  - 多試行化 -> 多項分布

---

### 事前分布とデータの数

先ほどは何も知らないというデータを置いた
$p(\theta) = Beta(1,1)$

過去の経験を通してコイン平均 0.5 で分散 0.05 ぐらいじゃないかなー
$p(\theta) = Beta(50,50)$

なんとしても裏が出てほしいお気持ち
$p(\theta) = Beta(1,99)$

---

結果
事前の信念が大きいほど、影響は小さくなる
![](img/03_prep_11_5050.png)

---

データが圧倒的にあれば?

謎の分布$\theta$から得たデータは 1000 回中 800 回とする

![](img/03_postp_1000.png)

データの比率が大きくなって観測値に収束していく

---

注意

- 計算上パラメータ a,b の加算で求められるのは、事後の確率分布がベータ関数という前提で確率推論から明らかにしただけ
- 事後分布は a,b が直接更新されるというわけではない
- このようにハイパーパラメータを直接更新するのは**経験ベイズ法**と呼ばれる
- 共役でない場合は実際にサンプリングをして分布を求める
  - 例 MCMC(マルコフ連鎖モンテカルロ法)

---

### ベイズ決定

$P(\theta|z)$を推定した後にどう使うのか

---

事後分布$P(\theta|z)$から$\theta$を取り出す

ベイズでは予測と意思決定のステップが明確に分かれている
同じ確率分布を得たとしても、意思決定者によって取り出す値が変わる

よく使われるのは MAP(Maximum a posteriori)推定

---

1. 失敗のリスクが高い時 -> 分布の 25%などの位置の$\theta$を使う
1. 失敗のリスクが低い時 -> 分布の 75%などの位置の$\theta$を使う

![height:300px](img/03_beta_decision.png)

---

## PyMC を用いた推定事例

スペースシャトル、チャレンジャー号の例

> 書籍[『Python で体験するベイズ推論 PyMC による MCMC 入門』](https://www.morikita.co.jp/books/book/3155?utm_content=buffer67712&utm_medium=social&utm_source=twitter.com&utm_campaign=buffer)のサンプルをもとに作っています
> オリジナルは[Bayesian Methods for Hackers](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers)にあります

---

1986 年 1 月 28 日
スペースシャトルプロジェクト 25 回目の打ち上げでチャレンジャー号が打ち上げから 73 秒後に爆発した事故。

事故は SRB(補助ロケット)の O-Ring が破損したこと。
設計としてはこの O-Ring の故障に対して敏感になっていたことが問題だった。

---

外気温含む要因と O-Ring の故障の情報は過去 24 回(内 1 回は海上で喪失)のデータが利用可能であり、7 回の破損が記録されている

![](img/03_challenger_data.png)

---

低温になるほど破損しているケースが増えている
事故が起こるか起こらないかを$p(t)$で
温度によって 0->1 に変化するのをモデルに起こしたい

ロジスティック関数$y=\frac{1}{1+e^{-(bx+a)}}$

---

ロジスティック関数$y=\frac{1}{1+e^{-(bx+a)}}$

- b 傾き
- a バイアス

![](img/03_logistic_curve.png)

---

この a,b の値に正規分布を置いて推定する
$Norm(\mu,\tau)$

精度$\tau = \frac{1}{\sigma}$で値が大きいほど分布が狭くなる

![](img/03_challenger_normal.png)

---

破損の有無${0,1}$はベルヌーイ分布で表現する

![](img/03_bernoulli.png)

---

今回のグラフィカルモデリング

〇が変数
□ が確率分布

![](img/03_challenger_gm.png)

---

PyMC3 を使って MCMC で推定した後のパラメータの分布
![](img/03_challenger_trace_graph.png)

---

推定結果(mean + 2.5, 97.5%tile)
![](img/03_challenger_result.png)

事故の可能性が 98.6%というのが計算できた

---

次回

- 連続確率分布
- 線形回帰
- カルマンフィルター
- MCMC
---

### 参考書籍

- 『入門ベイズ統計 意思決定の理論と発展』著: 松原望
- 『入門ベイズ統計 意思決定の理論と発展』著: 松原望
